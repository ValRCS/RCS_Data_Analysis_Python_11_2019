{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Corpora and Lexical Resources\n",
    "\n",
    "based on the NLTK book:\n",
    "\n",
    "[\"Accessing Text Corpora and Lexical Resources\"](https://www.nltk.org/book/ch02.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Text Corpora\n",
    "\n",
    "NLTK includes many text collections (corpora) and other language resources, listed here: http://www.nltk.org/nltk_data/\n",
    "\n",
    "Additional information:\n",
    "* [NLTK Corpus How-to](http://www.nltk.org/howto/corpus.html)\n",
    "\n",
    "In order to use these resources you may need to download them using `nltk.download()`\n",
    "\n",
    "---\n",
    "\n",
    "**NLTK book: [\"Text Corpus Structure\"](https://www.nltk.org/book/ch02#text-corpus-structure)**\n",
    "\n",
    "There are different types of corpora:\n",
    "* simple collections of text (e.g. Gutenberg corpus)\n",
    "* categorized (texts are grouped into categories that might correspond to genre, source, author)\n",
    "* temporal, demonstrating language use over a time period (e.g. news texts)\n",
    "\n",
    "![Types of NLTK corpora](https://www.nltk.org/images/text-corpus-structure.png)\n",
    "\n",
    "There are also annotated text corpora that contain linguistic annotations, representing POS tags, named entities, semantic roles, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Gutenberg Corpus\n",
    "\n",
    "NLTK includes a small selection of texts (= multiple files) from the Project Gutenberg electronic text archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore its contents:\n",
    "\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]\n"
     ]
    }
   ],
   "source": [
    "# \"Emma\" by Jane Austen\n",
    "\n",
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "\n",
    "print(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences:\n",
      "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ['CHAPTER', 'I']]\n",
      "\n",
      "Words:\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
      "\n",
      "Chars:\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can access corpus texts as characters, words (tokens) or sentences:\n",
    "\n",
    "file_id = 'austen-emma.txt'\n",
    "\n",
    "print(\"\\nSentences:\")\n",
    "print( nltk.corpus.gutenberg.sents(file_id)[:3] )\n",
    "\n",
    "print(\"\\nWords:\")\n",
    "print( nltk.corpus.gutenberg.words(file_id)[:10] )\n",
    "\n",
    "print(\"\\nChars:\")\n",
    "print( nltk.corpus.gutenberg.raw(file_id)[:50] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.nltk.org/book/ch02#gutenberg-corpus on how to compute statistics of words, sentences and characters (e.g. avg words per sentence).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Brown corpus\n",
    "\n",
    "The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University.\n",
    "\n",
    "This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brown corpus categories list:\n",
    "\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge', 'without', 'let', '.'], [\"Self's\", 'integrity', 'was', 'and', 'is', 'and', 'ever', 'had', 'been', '.']]\n"
     ]
    }
   ],
   "source": [
    "# We can filter the corpus by (a) one or more categories or (b) file IDs:\n",
    "\n",
    "print(brown.sents(categories='science_fiction')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.sents(categories=['news', 'editorial', 'reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.words(fileids=['cg22']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use NLTK **ConditionalFreqDist** to collect statistics on the corpus distribution across genres and other properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "           for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "table = cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brown corpus contains tags with part-of-speech information\n",
    "\n",
    "[Working with Tagged Corpora](https://www.nltk.org/book/ch05#tagged-corpora) (NLTK book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.corpus.brown.tagged_words(tagset='universal')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('jury', 'NOUN'),\n",
       " ('further', 'ADV'),\n",
       " ('said', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('term-end', 'NOUN'),\n",
       " ('presentments', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('City', 'NOUN'),\n",
       " ('Executive', 'ADJ'),\n",
       " ('Committee', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('had', 'VERB'),\n",
       " ('over-all', 'ADJ'),\n",
       " ('charge', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('election', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('deserves', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('praise', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('thanks', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('City', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('for', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('manner', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('the', 'DET'),\n",
       " ('election', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('conducted', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('September-October', 'NOUN'),\n",
       " ('term', 'NOUN'),\n",
       " ('jury', 'NOUN'),\n",
       " ('had', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('charged', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('Superior', 'ADJ'),\n",
       " ('Court', 'NOUN'),\n",
       " ('Judge', 'NOUN'),\n",
       " ('Durwood', 'NOUN'),\n",
       " ('Pye', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('investigate', 'VERB'),\n",
       " ('reports', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('possible', 'ADJ'),\n",
       " ('``', '.'),\n",
       " ('irregularities', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('hard-fought', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('was', 'VERB'),\n",
       " ('won', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Mayor-nominate', 'NOUN'),\n",
       " ('Ivan', 'NOUN'),\n",
       " ('Allen', 'NOUN'),\n",
       " ('Jr.', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('Only', 'ADV'),\n",
       " ('a', 'DET'),\n",
       " ('relative', 'ADJ'),\n",
       " ('handful', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('such', 'ADJ'),\n",
       " ('reports', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('received', 'VERB'),\n",
       " (\"''\", '.'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('considering', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('widespread', 'ADJ'),\n",
       " ('interest', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('election', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('number', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('voters', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('size', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('this', 'DET'),\n",
       " ('city', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('did', 'VERB'),\n",
       " ('find', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('many', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " (\"Georgia's\", 'NOUN'),\n",
       " ('registration', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('election', 'NOUN'),\n",
       " ('laws', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('are', 'VERB'),\n",
       " ('outmoded', 'ADJ'),\n",
       " ('or', 'CONJ'),\n",
       " ('inadequate', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('often', 'ADV'),\n",
       " ('ambiguous', 'ADJ'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('recommended', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('legislators', 'NOUN'),\n",
       " ('act', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('to', 'PRT'),\n",
       " ('have', 'VERB'),\n",
       " ('these', 'DET'),\n",
       " ('laws', 'NOUN'),\n",
       " ('studied', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('revised', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('end', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('modernizing', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('improving', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('grand', 'ADJ'),\n",
       " ('jury', 'NOUN'),\n",
       " ('commented', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('number', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('other', 'ADJ'),\n",
       " ('topics', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('among', 'ADP'),\n",
       " ('them', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('purchasing', 'VERB'),\n",
       " ('departments', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('it', 'PRON'),\n",
       " ('said', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('are', 'VERB'),\n",
       " ('well', 'ADV'),\n",
       " ('operated', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('follow', 'VERB'),\n",
       " ('generally', 'ADV'),\n",
       " ('accepted', 'VERB'),\n",
       " ('practices', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('inure', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('best', 'ADJ'),\n",
       " ('interest', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('both', 'DET'),\n",
       " ('governments', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('Merger', 'NOUN'),\n",
       " ('proposed', 'VERB'),\n",
       " ('However', 'ADV'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('believes', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('these', 'DET'),\n",
       " ('two', 'NUM'),\n",
       " ('offices', 'NOUN'),\n",
       " ('should', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('combined', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('achieve', 'VERB'),\n",
       " ('greater', 'ADJ'),\n",
       " ('efficiency', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('reduce', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('cost', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('administration', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('City', 'NOUN'),\n",
       " ('Purchasing', 'VERB'),\n",
       " ('Department', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('lacking', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('experienced', 'VERB'),\n",
       " ('clerical', 'ADJ'),\n",
       " ('personnel', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('result', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('city', 'NOUN'),\n",
       " ('personnel', 'NOUN'),\n",
       " ('policies', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('urged', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('city', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('take', 'VERB'),\n",
       " ('steps', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('remedy', 'VERB'),\n",
       " (\"''\", '.'),\n",
       " ('this', 'DET'),\n",
       " ('problem', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Implementation', 'NOUN'),\n",
       " ('of', 'ADP')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# islice() lets us read a part of the corpus\n",
    "\n",
    "from itertools import islice\n",
    "words = islice(words, 300)\n",
    "\n",
    "# let's convert it to a list\n",
    "word_list = list(words)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grand',\n",
       " 'recent',\n",
       " 'Executive',\n",
       " 'over-all',\n",
       " 'Superior',\n",
       " 'possible',\n",
       " 'hard-fought',\n",
       " 'relative',\n",
       " 'such',\n",
       " 'widespread',\n",
       " 'many',\n",
       " 'outmoded',\n",
       " 'inadequate',\n",
       " 'ambiguous',\n",
       " 'grand',\n",
       " 'other',\n",
       " 'best',\n",
       " 'greater',\n",
       " 'clerical']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all words with POS tag \"ADJ\"\n",
    "\n",
    "tag = 'ADJ'\n",
    "\n",
    "[item[0] for item in word_list if item[1] == tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional examples** (using FreqDist, ...):\n",
    "    \n",
    "[Working with Tagged Corpora](https://www.nltk.org/book/ch05#tagged-corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) NLTK Corpus functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fileids()  = the files of the corpus\n",
    "* fileids([categories])  = the files of the corpus corresponding to these categories\n",
    "\n",
    "* categories()  = the categories of the corpus\n",
    "* categories([fileids])  = the categories of the corpus corresponding to these files\n",
    "\n",
    "* raw()  = the raw content of the corpus\n",
    "* raw(fileids=[f1,f2,f3])  = the raw content of the specified files\n",
    "* raw(categories=[c1,c2])  = the raw content of the specified categories\n",
    "\n",
    "* words()  = the words of the whole corpus\n",
    "* words(fileids=[f1,f2,f3])  = the words of the specified fileids\n",
    "* words(categories=[c1,c2])  = the words of the specified categories\n",
    "\n",
    "* sents()  = the sentences of the whole corpus\n",
    "* sents(fileids=[f1,f2,f3])  = the sentences of the specified fileids\n",
    "* sents(categories=[c1,c2])  = the sentences of the specified categories\n",
    "\n",
    "* abspath(fileid)  = the location of the given file on disk\n",
    "* encoding(fileid)  = the encoding of the file (if known)\n",
    "* open(fileid)  = open a stream for reading the given corpus file\n",
    "* root  = if the path to the root of locally installed corpus\n",
    "\n",
    "* readme()  = the contents of the README file of the corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: if you want to explore these corpora using `nltk.Text` functionality (e.g. as in the Introduction part) you will need to load them into `nltk.Text`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn!\n",
    "\n",
    "Choose one of NLTK corpora and **explore it using NLTK** (following examples here and in the NLTK book).\n",
    "\n",
    "Also apply what you learned (FreqDist, ...) in section \"Computing with Language: Statistics\".\n",
    "\n",
    "---\n",
    "\n",
    "**Write code in notebook cells below**.\n",
    "* add more cells (use \"+\" icon) if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Resources\n",
    "\n",
    "A lexicon, or lexical resource, is a collection of words and/or phrases along with associated information such as part of speech and sense definitions.\n",
    "\n",
    "https://www.nltk.org/book/ch02#lexical-resources\n",
    "\n",
    "We already used NLTK lexical resources (stopwords and common English words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but with a richer structure. NLTK includes the English WordNet, with 155,287 words and 117,659 synonym sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('wind.n.01'),\n",
       " Synset('wind.n.02'),\n",
       " Synset('wind.n.03'),\n",
       " Synset('wind.n.04'),\n",
       " Synset('tip.n.03'),\n",
       " Synset('wind_instrument.n.01'),\n",
       " Synset('fart.n.01'),\n",
       " Synset('wind.n.08'),\n",
       " Synset('weave.v.04'),\n",
       " Synset('wind.v.02'),\n",
       " Synset('wind.v.03'),\n",
       " Synset('scent.v.02'),\n",
       " Synset('wind.v.05'),\n",
       " Synset('wreathe.v.03'),\n",
       " Synset('hoist.v.01')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a collection of synonym sets related to \"wind\"\n",
    "\n",
    "wn.synsets('wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn.synsets('get'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wind', 'winding', 'twist']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words (lemmas) in one of synsets:\n",
    "\n",
    "wn.synset('wind.n.08').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the act of winding or twisting'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('wind.n.08').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he put the key in the old clock and gave it a good wind']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('wind.n.08').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wind', 'air_current', 'current_of_air']\n",
      "['wind']\n",
      "['wind']\n",
      "['wind', 'malarkey', 'malarky', 'idle_words', 'jazz', 'nothingness']\n",
      "['tip', 'lead', 'steer', 'confidential_information', 'wind', 'hint']\n",
      "['wind_instrument', 'wind']\n",
      "['fart', 'farting', 'flatus', 'wind', 'breaking_wind']\n",
      "['wind', 'winding', 'twist']\n",
      "['weave', 'wind', 'thread', 'meander', 'wander']\n",
      "['wind', 'twist', 'curve']\n",
      "['wind', 'wrap', 'roll', 'twine']\n",
      "['scent', 'nose', 'wind']\n",
      "['wind', 'wind_up']\n",
      "['wreathe', 'wind']\n",
      "['hoist', 'lift', 'wind']\n"
     ]
    }
   ],
   "source": [
    "# let's explore all the synsets for this word\n",
    "\n",
    "for synset in wn.synsets('wind'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('curve.n.01.curve'),\n",
       " Lemma('curve.n.02.curve'),\n",
       " Lemma('curve.n.03.curve'),\n",
       " Lemma('curvature.n.03.curve'),\n",
       " Lemma('bend.n.03.curve'),\n",
       " Lemma('swerve.v.01.curve'),\n",
       " Lemma('wind.v.02.curve'),\n",
       " Lemma('arch.v.01.curve'),\n",
       " Lemma('crook.v.01.curve'),\n",
       " Lemma('curl.v.01.curve')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see all synsets that contain a given word\n",
    "\n",
    "wn.lemmas('curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('wind.n.01'),\n",
       " Synset('wind.n.02'),\n",
       " Synset('wind.n.03'),\n",
       " Synset('wind.n.04'),\n",
       " Synset('tip.n.03'),\n",
       " Synset('wind_instrument.n.01'),\n",
       " Synset('fart.n.01'),\n",
       " Synset('wind.n.08'),\n",
       " Synset('weave.v.04'),\n",
       " Synset('wind.v.02'),\n",
       " Synset('wind.v.03'),\n",
       " Synset('scent.v.02'),\n",
       " Synset('wind.v.05'),\n",
       " Synset('wreathe.v.03'),\n",
       " Synset('hoist.v.01')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysyn = wn.synsets('wind')\n",
    "mysyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wind', 'air_current', 'current_of_air'],\n",
       " ['wind'],\n",
       " ['wind'],\n",
       " ['wind', 'malarkey', 'malarky', 'idle_words', 'jazz', 'nothingness'],\n",
       " ['tip', 'lead', 'steer', 'confidential_information', 'wind', 'hint'],\n",
       " ['wind_instrument', 'wind'],\n",
       " ['fart', 'farting', 'flatus', 'wind', 'breaking_wind'],\n",
       " ['wind', 'winding', 'twist'],\n",
       " ['weave', 'wind', 'thread', 'meander', 'wander'],\n",
       " ['wind', 'twist', 'curve'],\n",
       " ['wind', 'wrap', 'roll', 'twine'],\n",
       " ['scent', 'nose', 'wind'],\n",
       " ['wind', 'wind_up'],\n",
       " ['wreathe', 'wind'],\n",
       " ['hoist', 'lift', 'wind']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = [syn.lemma_names() for syn in wn.synsets('wind') ]\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['wind', 'air_current', 'current_of_air']\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(mylist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wind air_current current_of_air',\n",
       " 'wind',\n",
       " 'wind',\n",
       " 'wind malarkey malarky idle_words jazz nothingness',\n",
       " 'tip lead steer confidential_information wind hint',\n",
       " 'wind_instrument wind',\n",
       " 'fart farting flatus wind breaking_wind',\n",
       " 'wind winding twist',\n",
       " 'weave wind thread meander wander',\n",
       " 'wind twist curve',\n",
       " 'wind wrap roll twine',\n",
       " 'scent nose wind',\n",
       " 'wind wind_up',\n",
       " 'wreathe wind',\n",
       " 'hoist lift wind']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystrings = [\" \".join(line) for line in mylist]\n",
    "mystrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wind|||air_current|||current_of_air'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"|||\".join(mylist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mytext.txt', 'w') as f:\n",
    "    f.write(\"Just some text\\n2nd line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mysyn.txt', 'w') as f:\n",
    "    f.writelines(mystrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mysyn2.txt', 'w') as f:\n",
    "    for line in mystrings:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Additional WordNet examples:**\n",
    "* https://www.nltk.org/book/ch02#wordnet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
